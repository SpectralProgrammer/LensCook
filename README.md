# LensCook

## LensCook: Let’s Cook Together

LensCook is a web and mobile application that recommends diverse, healthy recipes based on photographed ingredients. Originally developed during a 36-hour hackathon, the app integrates the **Google Cloud Vision API** and **Spoonacular API** to analyze user-submitted food images and return relevant recipe suggestions.

Users can either take a photo using the in-app camera or upload an image of ingredients from their device. LensCook then identifies the ingredients and suggests recipes that promote a nutritious and varied diet.

> ⚠️ **Note:** Due to the expiration of third-party API keys, certain features may not be fully functional until the keys are updated.

## 🏆 Recognition

- 🥇 **First Place Winner** — *Health and Wellness* category
- 👥 Developed by a team of four during a 36-hour hackathon with 200+ participants

## 📺 Demo

[![Watch the demo](https://img.youtube.com/vi/rtS5ua4Xm2k/0.jpg)](https://www.youtube.com/watch?v=rtS5ua4Xm2k&t=3625s)  
[Click here to watch the full demonstration](https://www.youtube.com/watch?v=rtS5ua4Xm2k&t=3625s)

## 🔧 Technologies Used

- **Frontend (Web):** Streamlit, CSS  
- **Mobile Prototype:** Flutter  
- **Backend:** Python, Firebase, REST API  
- **APIs:** Google Cloud Vision API, Spoonacular API

## 🚀 Features

- Upload or capture images of ingredients using in-app camera
- Ingredient detection via Google Cloud Vision API
- Recipe suggestions powered by Spoonacular API
- Responsive web interface with Streamlit
- Mobile prototype using Flutter with Firebase integration
